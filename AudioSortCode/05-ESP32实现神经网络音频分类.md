
[【2022寒假在家练】ESP32实现神经网络音频分类 (eetree.cn)](https://www.eetree.cn/project/detail/1047)

# ESP32-S2实现神经网络音频分类：原理讲解与效果展示

## 一、信号采样与预处理

### 1. 采样率配置
- **硬件**：使用ESP32-S2的ADC（模拟数字转换器）。
- **采样率**：配置为20kHz。人耳听到的音频范围是20Hz到20kHz，为了准确还原20kHz的音频，采样率需要达到40kHz。
- **注意**：高频音频不太关注，因此20kHz的采样率足以覆盖所有需要的声音。

### 2. 使用DMA传输数据
- **硬件**：ESP32-S2内部的DMA（直接内存访问）模块。
- **缓冲区配置**：使用6个DMA缓冲区，每个缓冲区单通道，单位为1.16（每个数据两字节），每个缓冲区存放256个数据。
- **数据传输**：DMA自动读取ADC电压并将其放入DMA缓冲区，每次填充完毕后产生中断，记录采样位置。

### 3. 数据采集与预处理
- **采样数据**：从DMA缓冲区提取连续的1024个数据点（大约0.05秒）。
- **重采样**：每隔512个点重新提取1024个点。
- **数据映射**：将0到4096的ADC值映射到-1到1的float32浮点数区间。

### 4. 傅里叶变换
- **工具**：使用实数傅里叶变换库（如KissFFT）。
- **变换过程**：对1024个点进行傅里叶变换（FFT），得到频率能量分布。
- **结果处理**：由于FFT结果关于轴对称，实际有用的数据为前512个点。

### 5. 梅尔频谱变换
![[deepNetworkDesigner#深度学习实用指南：从数据到部署]]
- **滤波器**：应用梅尔滤波器，对低频用窄滤波器，高频用宽滤波器。
- **结果处理**：得到30个频率能量点的数组，形成长度为30的数组。
- **频谱图**：拼接得到最终的频谱图（40列，每列表示一个时间段的频谱信息）。

## 二、神经网络的训练与分类实现

### 1. 训练数据与模型结构
- **数据集**：使用ESC-10数据集（Environmental Sound Classification），包含10类，每类40个音频样本，共400个样本。
- **数据预处理**：将采集到的音频数据转换为40x30的频谱图像。

### 2. CNN结构
- **模型工具**：使用Keras和TensorFlow框架进行模型构建和训练。
- **网络结构**：
  - 输入：40x30单通道图像。
  - 卷积层：多层卷积和池化，提取特征。
  - 展开层：将卷积特征展开为一维数组（长度280）。
  - 全连接层：将展开的特征通过全连接层，输出10个分类结果。

### 3. 模型训练
- **训练过程**：使用ESC-10数据集进行训练，迭代10次，每次遍历所有数据。
- **训练结果**：在训练集上的准确率达到60%-70%。

### 4. 模型部署
- **转换工具**：编写脚本将Keras模型权重转换为C代码格式。
- **部署平台**：ESP32-S2，使用C语言实现卷积、池化和全连接层，将模型部署到ESP32-S2上运行。

## 三、程序操作逻辑

### 1. 按键功能
- **四个按键**：SW1到SW4。
  - SW1：DAC开关。
  - SW2：ADC开关。
  - SW3和SW4：调整设置。

### 2. 模式介绍
- **四种模式**：
  - FFT结果展示。
  - 示波器。
  - 梅尔频谱展示。
  - 分类结果展示。

### 3. 程序执行流程
- **FreeRTOS任务**：启用IO任务检测按键并切换模式，ADC任务负责采集音频数据和分类。
- **梅尔频谱与分类**：收集一秒钟音频并处理，分类结果每2秒更新一次。

## 四、效果展示

### 1. 代码展示
- **主要模块**：主函数、音频处理模块和神经网络实现部分。

### 2. 实际效果
- **展示分类结果**：将板子上电，按键切换模式，展示分类结果。
- **分类效果**：受限于内存和训练数据集规模，效果一般。

### 3. 未来优化
- **内存扩展**：增加内存和扩展数据集来优化分类性能。
